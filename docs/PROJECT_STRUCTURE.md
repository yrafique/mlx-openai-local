# ğŸ“ MLX OpenAI Local - Project Structure

**Last Updated:** October 18, 2025

---

## ğŸ“‚ Directory Structure

```
mlx-openai-local/
â”œâ”€â”€ ğŸ“ .claude/                    # Claude Code configuration
â”‚   â””â”€â”€ settings.local.json
â”‚
â”œâ”€â”€ ğŸ“ .venv/                      # Python virtual environment
â”‚   â””â”€â”€ (all dependencies)
â”‚
â”œâ”€â”€ ğŸ“ examples/                   # LangChain integration examples
â”‚   â”œâ”€â”€ langchain_basic.py         # Basic chat example
â”‚   â”œâ”€â”€ langchain_function_calling.py  # Function calling with agents
â”‚   â”œâ”€â”€ langchain_streaming.py     # Streaming responses
â”‚   â””â”€â”€ README.md                  # Examples documentation
â”‚
â”œâ”€â”€ ğŸ“ logs/                       # Server logs
â”‚   â”œâ”€â”€ api.log                    # API server logs
â”‚   â”œâ”€â”€ server_YYYYMMDD.log        # Daily server logs
â”‚   â””â”€â”€ ui.log                     # UI server logs
â”‚
â”œâ”€â”€ ğŸ“ models/                     # Downloaded MLX models
â”‚   â”œâ”€â”€ mlx-community--Qwen2.5-0.5B-Instruct-4bit/
â”‚   â”œâ”€â”€ mlx-community--Qwen2.5-3B-Instruct-4bit/
â”‚   â””â”€â”€ (other models as downloaded)
â”‚
â”œâ”€â”€ ğŸ“ scripts/                    # Management scripts
â”‚   â””â”€â”€ orchestrate.sh             # Start/stop/restart servers
â”‚
â”œâ”€â”€ ğŸ“ server/                     # Main server code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                     # Main API server (MLX Omni Server)
â”‚   â”œâ”€â”€ model_manager.py           # Model loading/management
â”‚   â”œâ”€â”€ openai_schemas.py          # OpenAI API schemas
â”‚   â”œâ”€â”€ smart_router.py            # Request routing logic
â”‚   â”œâ”€â”€ utils.py                   # Utility functions
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ tools/                  # Tool/function implementations
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ calculator.py          # Math calculator tool
â”‚       â”œâ”€â”€ web_search.py          # Basic web search (raw results)
â”‚       â”œâ”€â”€ web_search_stub.py     # Legacy stub
â”‚       â””â”€â”€ enhanced_web_search.py # â­ AI-processed web search
â”‚
â”œâ”€â”€ ğŸ“ tests/                      # Test files
â”‚   â”œâ”€â”€ test_chat.py               # Chat endpoint tests
â”‚   â””â”€â”€ test_smoke.sh              # Smoke tests
â”‚
â”œâ”€â”€ ğŸ“ ui/                         # Streamlit control panel
â”‚   â””â”€â”€ ControlPanel.py            # Main UI application
â”‚
â”œâ”€â”€ ğŸ“„ .env                        # Environment configuration
â”œâ”€â”€ ğŸ“„ .env.example                # Example environment file
â”œâ”€â”€ ğŸ“„ .gitignore                  # Git ignore rules
â”‚
â”œâ”€â”€ ğŸ“„ pyproject.toml              # Poetry configuration
â”œâ”€â”€ ğŸ“„ requirements.txt            # Pip dependencies
â”‚
â”œâ”€â”€ ğŸ“„ README.md                   # Main documentation
â”œâ”€â”€ ğŸ“„ ENHANCED_WEB_SEARCH.md      # â­ Enhanced search guide
â”œâ”€â”€ ğŸ“„ WEB_SEARCH_READY.md         # Basic search setup
â”œâ”€â”€ ğŸ“„ TOOL_CALLING_GUIDE.md       # Function calling guide
â”œâ”€â”€ ğŸ“„ FUNCTION_CALLING_STATUS.md  # Function calling status
â”œâ”€â”€ ğŸ“„ MIGRATION_COMPLETE.md       # Migration notes
â”œâ”€â”€ ğŸ“„ ORCHESTRATION_SCRIPT_UPDATE.md
â”œâ”€â”€ ğŸ“„ REAL_WEBSEARCH_INTEGRATION.md
â”œâ”€â”€ ğŸ“„ SUCCESS.md                  # Success metrics
â”œâ”€â”€ ğŸ“„ TEST_RESULTS.md             # Test results
â”‚
â”œâ”€â”€ ğŸ“„ api.pid                     # API server process ID
â”œâ”€â”€ ğŸ“„ ui.pid                      # UI server process ID
â”‚
â””â”€â”€ ğŸ“„ test_*.py, test_*.json      # Various test files
```

---

## ğŸ”‘ Key Files

### Core Server Files

| File | Purpose | Dependencies |
|------|---------|--------------|
| `server/app.py` | Main API server, uses MLX Omni Server | mlx-omni-server |
| `server/model_manager.py` | Model loading and caching | mlx, mlx-lm |
| `server/openai_schemas.py` | OpenAI API compatibility | pydantic |
| `server/smart_router.py` | Request routing logic | - |

### Tool Implementations

| File | Purpose | Type |
|------|---------|------|
| `server/tools/calculator.py` | Math evaluation | Basic |
| `server/tools/web_search.py` | Web search (raw results) | Basic |
| `server/tools/enhanced_web_search.py` | **AI-processed web search** | **Enhanced** |

### UI & Control

| File | Purpose | Framework |
|------|---------|-----------|
| `ui/ControlPanel.py` | Web UI for testing and monitoring | Streamlit |
| `scripts/orchestrate.sh` | Server management (start/stop/restart) | Bash |

### Documentation

| File | Contents |
|------|----------|
| `README.md` | Main project documentation |
| `ENHANCED_WEB_SEARCH.md` | Enhanced web search guide (NEW) |
| `WEB_SEARCH_READY.md` | Basic web search setup |
| `TOOL_CALLING_GUIDE.md` | Function calling guide |

---

## ğŸ§© Component Interaction

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User/Client   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    HTTP Request
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         server/app.py (Port 7007)           â”‚
â”‚  - OpenAI-compatible API                     â”‚
â”‚  - Uses MLX Omni Server                      â”‚
â”‚  - 99% function calling accuracy             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚
          â”‚                      â”‚
    Regular Chat          Function Calling
          â”‚                      â”‚
          â†“                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  model_manager.py   â”‚  â”‚   tools/         â”‚
â”‚  - Load models      â”‚  â”‚   - calculator   â”‚
â”‚  - MLX inference    â”‚  â”‚   - web_search   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   - enhanced_*   â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                         Enhanced Tool Uses:
                                    â”‚
                                    â†“
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  _call_local_llm â”‚
                         â”‚  (synthesize)    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸŒŸ Enhanced Web Search Architecture

### Flow Diagram

```
User Query: "What's the weather in Ottawa?"
           â”‚
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ControlPanel.py â”‚  (UI)
    â”‚  Mode: Enhanced  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
        POST /v1/chat/completions
             â”‚
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    server/app.py    â”‚
    â”‚  (MLX Omni Server)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    Detects tool need (99% accuracy)
             â”‚
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  tools/enhanced_web_search â”‚
    â”‚  get_weather_enhanced()    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
      â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
      â”‚           â”‚
   Search      Synthesize
   DuckDuckGo   (LLM call)
      â”‚           â”‚
      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
            â”‚
    Return processed answer
            â”‚
            â†“
         User gets:
    "Ottawa: 10Â°C, partly cloudy..."
```

---

## ğŸ“¦ Dependencies

### Core Dependencies

```toml
[tool.poetry.dependencies]
python = "^3.12"

# MLX and AI
mlx = "^0.22.7"
mlx-lm = "^0.22.0"
mlx-omni-server = "^0.1.6"      # 99% function calling

# Web & API
fastapi = "^0.115.6"
uvicorn = "^0.34.0"
aiohttp = "^3.13.1"
requests = "^2.32.3"

# UI
streamlit = "^1.41.1"

# Tools
ddgs = "^9.6.1"                 # DuckDuckGo search
python-dotenv = "^1.0.1"

# Utilities
pydantic = "^2.10.5"
numpy = "^1.26.4"
```

### Development Dependencies

```toml
[tool.poetry.group.dev.dependencies]
pytest = "^8.3.4"
langchain = "^0.3.15"
langchain-openai = "^0.2.13"
```

### Installation

```bash
# Using pip
pip3 install -r requirements.txt

# Using poetry
poetry install
```

---

## ğŸ”§ Configuration Files

### `.env` - Environment Variables

```bash
# Server Configuration
API_HOST=0.0.0.0
API_PORT=7007
UI_PORT=7006

# Model Configuration
DEFAULT_MODEL=mlx-community/Qwen2.5-3B-Instruct-4bit
ALLOWED_MODELS=mlx-community/Qwen2.5-0.5B-Instruct-4bit,mlx-community/Qwen2.5-3B-Instruct-4bit

# Model Cache
MODEL_CACHE_DIR=./models

# Generation Settings
MAX_TOKENS=512
TEMPERATURE=0.7
TOP_P=0.95

# API Settings (for enhanced search)
OPENAI_API_BASE=http://localhost:7007/v1

# Optional
HF_TOKEN=your_huggingface_token
```

### `pyproject.toml` - Poetry Configuration

Project metadata, dependencies, and build configuration.

---

## ğŸš€ Server Management

### Process IDs

- `api.pid` - API server process ID
- `ui.pid` - UI server process ID

### Log Files

- `logs/api.log` - API server logs
- `logs/ui.log` - UI server logs
- `logs/server_YYYYMMDD.log` - Daily logs

### Management Commands

```bash
# Start all servers
./scripts/orchestrate.sh --start

# Stop all servers
./scripts/orchestrate.sh --stop

# Restart all servers
./scripts/orchestrate.sh --restart

# Check status
./scripts/orchestrate.sh --status
```

---

## ğŸ§ª Testing Structure

### Unit Tests
- `tests/test_chat.py` - Chat API tests
- `test_model.py` - Model loading tests
- `test_direct_tool.py` - Tool execution tests

### Integration Tests
- `test_chat.json` - Chat request payload
- `test_function_call.json` - Function calling payload
- `test_weather.json` - Weather tool payload
- `test_websearch_tool.json` - Web search payload

### Smoke Tests
- `tests/test_smoke.sh` - Quick health checks

---

## ğŸ“Š Model Storage

Models are cached in `models/` directory:

```
models/
â”œâ”€â”€ mlx-community--Qwen2.5-0.5B-Instruct-4bit/
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ mlx-community--Qwen2.5-3B-Instruct-4bit/
â”‚   â””â”€â”€ (same structure)
â”‚
â””â”€â”€ models--mlx-community--{model-name}/
    â””â”€â”€ refs/
```

**Storage Requirements:**
- 0.5B model: ~500MB
- 3B model: ~2-4GB
- 7B model: ~5-8GB

---

## ğŸ” Finding Files

### By Purpose

**Need to modify API behavior?**
â†’ `server/app.py`

**Need to add a new tool?**
â†’ `server/tools/` (create new .py file)

**Need to change UI?**
â†’ `ui/ControlPanel.py`

**Need to adjust model settings?**
â†’ `.env`

**Need to update dependencies?**
â†’ `requirements.txt` or `pyproject.toml`

### By Feature

**Function Calling:**
- Implementation: `server/app.py` (MLX Omni Server)
- Tools: `server/tools/`
- Examples: `examples/langchain_function_calling.py`

**Web Search (Basic):**
- Implementation: `server/tools/web_search.py`
- Documentation: `WEB_SEARCH_READY.md`

**Web Search (Enhanced):**
- Implementation: `server/tools/enhanced_web_search.py`
- Documentation: `ENHANCED_WEB_SEARCH.md`
- UI Integration: `ui/ControlPanel.py`

---

## ğŸ¯ Quick Navigation

| I want to... | Go to... |
|--------------|----------|
| Start the server | `./scripts/orchestrate.sh --start` |
| Test in browser | http://localhost:7006 |
| Add a new tool | `server/tools/` |
| Change model | `.env` â†’ `DEFAULT_MODEL` |
| See logs | `logs/` directory |
| Run examples | `examples/` directory |
| Read docs | `*.md` files in root |
| Test enhanced search | `python3 server/tools/enhanced_web_search.py` |

---

## ğŸ“š Documentation Index

1. **README.md** - Project overview, quick start
2. **ENHANCED_WEB_SEARCH.md** - AI-processed web search guide
3. **WEB_SEARCH_READY.md** - Basic web search setup
4. **TOOL_CALLING_GUIDE.md** - Function calling tutorial
5. **PROJECT_STRUCTURE.md** - This file
6. **examples/README.md** - LangChain examples

---

## ğŸ”„ Update History

- **Oct 18, 2025** - Added enhanced web search
- **Oct 18, 2025** - Integrated MLX Omni Server (99% function calling)
- **Oct 17, 2025** - Added basic web search
- **Oct 15, 2025** - Initial project structure

---

**Status:** âœ… **Well-Organized & Production-Ready**
**Version:** 2.0
