[tool.poetry]
name = "mlx-openai-local"
version = "2.0.0"
description = "MLX Omni Server - Local LLM with 99% Function Calling Accuracy"
authors = ["Your Name <your.email@example.com>"]
readme = "README.md"
package-mode = false

[tool.poetry.dependencies]
python = "^3.11"
mlx-omni-server = ">=0.3.4"
langchain = ">=0.2.0"
langchain-community = ">=0.2.0"
langchain-openai = ">=0.1.0"
langgraph = ">=0.0.40"
streamlit = ">=1.30.0"
huggingface-hub = ">=0.20.0"
python-dotenv = ">=1.0.0"
requests = ">=2.31.0"
pydantic = ">=2.5.0"
duckduckgo-search = ">=4.0.0"
matplotlib = ">=3.7.0"
pandas = ">=2.0.0"
plotly = ">=5.17.0"
openpyxl = ">=3.1.0"
pyttsx3 = ">=2.90"
openai-whisper = ">=20230314"
pillow = ">=10.0.0"
numpy = ">=1.24.0"

[tool.poetry.group.dev.dependencies]
pytest = "^7.4.0"
httpx = "^0.26.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
