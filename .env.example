# OpenAI-style configuration
OPENAI_API_BASE=http://localhost:7007/v1
OPENAI_API_KEY=local-demo-key

# Server configuration
API_HOST=0.0.0.0
API_PORT=7007
UI_PORT=7006

# Model selection
DEFAULT_MODEL=mlx-community/TinyLlama-1.1B-Chat-v1.0-mlx
ALLOWED_MODELS=mlx-community/TinyLlama-1.1B-Chat-v1.0-mlx,mlx-community/Qwen2.5-1.5B-Instruct-mlx

# Hugging Face
HF_TOKEN=
MODEL_CACHE_DIR=./models

# Performance tuning
MAX_TOKENS=512
TEMPERATURE=0.7
TOP_P=0.95

# Logging
LOG_LEVEL=INFO
LOG_DIR=./logs
